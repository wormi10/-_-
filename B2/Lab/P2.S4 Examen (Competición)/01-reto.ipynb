{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0YtWLxhKnqn"
      },
      "source": [
        "# Reto: competición de sistemas de clasificación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fisk02EKnqu"
      },
      "source": [
        "En este reto aplicaremos regresión logística a la tarea de clasificación [*california-housing*](https://scikit-learn.org/1.5/datasets/real_world.html#california-housing-dataset).\n",
        "\n",
        "El objetivo de esta tarea es clasificar, con mínimo error, diferentes distritos del estado de California (EEUU) en 6 clases diferentes correspondientes a rangos de precios medios de vivienda, utilizando un conjunto de D=8 características numéricas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUgZcQZXKnqw"
      },
      "source": [
        "## 1. Obtención del corpus y partición de datos\n",
        "\n",
        "Ejecuta el siguiente bloque de código, en el que importamos las librerías necesarias, definimos constantes, obtenemos el dataset, barajamos (con una semilla concreta e inalterable) y particionamos los datos en train y test (con una proporción concreta e inalterable).\n",
        "\n",
        "**MUY IMPORTANTE: NO MODIFICAR ESTE BLOQUE DE CÓDIGO, SOLO EJECUTAR.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wzx6suapKnqy",
        "outputId": "f0702735-62be-44a3-c72c-db6459cd7df9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******** INFORMACIÓN BÁSICA DEL DATASET **********\n",
            "D=8, C=6, N_train=16512, N_test=4128\n"
          ]
        }
      ],
      "source": [
        "### NO MODIFIQUES ESTE BLOQUE DE CÓDIGO; SOLO EJECÚTALO ###\n",
        "\n",
        "import warnings; warnings.filterwarnings(\"ignore\"); import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "RANDOM_SEED = 22\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "### NO MODIFIQUES ESTE BLOQUE DE CÓDIGO; SOLO EJECÚTALO ###\n",
        "\n",
        "corp = fetch_california_housing()\n",
        "X = corp.data.astype(np.float16) # muestras\n",
        "y = corp.target.astype(np.uint)  # etiquetas de clase\n",
        "\n",
        "### NO MODIFIQUES ESTE BLOQUE DE CÓDIGO; SOLO EJECÚTALO ###\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
        "D = X_train.shape[1]; C=np.unique(y_train).size; Ntr = X_train.shape[0]; Nte = X_test.shape[0];\n",
        "\n",
        "print(\"******** INFORMACIÓN BÁSICA DEL DATASET **********\")\n",
        "print(f\"D={D}, C={C}, N_train={Ntr}, N_test={Nte}\")\n",
        "\n",
        "### NO MODIFIQUES ESTE BLOQUE DE CÓDIGO; SOLO EJECÚTALO ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhjB0jltKnq2"
      },
      "source": [
        "## 2. Entrenamiento y evaluación del sistema base (baseline)\n",
        "\n",
        "A continuación podéis obtener una tasa de error de referencia, obtenido con un clasificador de regresión logística entrenado con `tol=0.01`, `C=1`, y `max_iter=10`. Este será nuestro sistema de clasificación base (baseline).\n",
        "\n",
        "Vuestro objetivo será mejorar (lo máximo posible) la tasa de error obtenida con este sistema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vx3-ucXVKnq4",
        "outputId": "8e0fb2e1-fd99-4c49-cfe8-8a352b1f2b13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error de clasificación en test (baseline):  59.9%\n"
          ]
        }
      ],
      "source": [
        "# NOTA IMPORTANTE: SIEMPRE USAREMOS random_state=RANDOM_SEED\n",
        "clf = LogisticRegression(random_state=RANDOM_SEED, C=1, tol=0.01, max_iter=10).fit(X_train, y_train)\n",
        "err_test = (1 - accuracy_score(y_test, clf.predict(X_test)))*100\n",
        "print(f'Error de clasificación en test (baseline): {err_test:5.1f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBXcsOX2Knq6"
      },
      "source": [
        "## 3. Exploración/Optimización de hiperparámetros\n",
        "\n",
        "Realiza una exploración y ajuste de los hiperparámetros tolerancia (`tol`), escalado del factor de regularización (`C`), y número de iteraciones máximas (`max_iter`), para minimizar la tasa de error de clasificación en test.\n",
        "\n",
        "Reporta los resultados de los experimentos en una o varias tablas que muestren los valores de los tres hiperparámetros mencionados, además de las tasas de error de clasificación en train y test.\n",
        "\n",
        "Introduce a continuación el código que hayas utilizado para realizar esta exploración/optimización, y asegúrate que el cuaderno conserva la salida de la ejecución de dicho código. Crea celdas de código adicionales si lo necesitas.\n",
        "\n",
        "**IMPORTANTE: usa el parámetro `random_state=RANDOM_SEED` en `LogisticRegression()`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BkIYbw6BKnq8"
      },
      "outputs": [],
      "source": [
        "#### COMPLETAR!\n",
        "\n",
        "# ¡¡¡¡OBLIGATORIO!!!! random_state=RANDOM_SEED en LogisticRegression()\n",
        "\n",
        "# Asegúrate que entregas el cuaderno con la salida (la tabla de resultados con la exploración)\n",
        "\n",
        "# Puedes añadir tantas celdas de código como desees para explorar los parámetros del clasificador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGMpaBKLKnq9"
      },
      "source": [
        "## 4. Determinación de los hiperparámetros óptimos y tasas de error\n",
        "\n",
        "Por último, **modifica** la siguiente celda para que indique cuáles son los valores óptimos de los tres hiperparámetros `C`, `tol` y `max_iter`, así como las correspondientes tasas de error obtenidas en los conjuntos de entrenamiento y test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skpGzTigKnq_"
      },
      "source": [
        "- **Factor de regularización (`C`):**\n",
        "- **Tolerancia (`tol`):**\n",
        "- **Número máximo de iteraciones (`max_iter`):**\n",
        "- **Tasa de error (%) obtenida en train:**\n",
        "- **Tasa de error (%) obtenida en test:**\n",
        "\n",
        "\n",
        "Nota: los valores de `C`, `tol` y `max_iter` que indiques aquí son los que usarás para participar en la evaluación final."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_c = None\n",
        "best_tol = None\n",
        "best_max_iter = None\n",
        "min_err_test = float('inf')\n",
        "\n",
        "print(\"|{:>10s} \\t|{:>10s} \\t|{:>7s} \\t|{:>11s}\\t |{:>11s}|\".format(\n",
        "    \"C\", \"tol\", \"max_it\", \"Err_train\", \"Err_test\"\n",
        "))\n",
        "print(\"-\" * 78)\n",
        "\n",
        "\n",
        "for tol in (1e-4, 1e-2, 1, 1e2, 1e4):\n",
        "    for C in (1e-4, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2):\n",
        "        for max_iter in (10, 25, 50, 100):\n",
        "\n",
        "            model = LogisticRegression(\n",
        "                tol=tol,\n",
        "                C=C,\n",
        "                random_state=22,\n",
        "                max_iter=max_iter\n",
        "            ).fit(X_train, y_train)\n",
        "\n",
        "            err_train = 1 - accuracy_score(y_train, model.predict(X_train))\n",
        "            err_test = 1 - accuracy_score(y_test, model.predict(X_test))\n",
        "\n",
        "            print(\"{:10.4f}\\t|{:10.1e}\\t|{:7d}\\t|{:11.2f}\\t|{:11.2f}\".format(\n",
        "                C, tol, max_iter, err_train * 100, err_test * 100\n",
        "            ))\n",
        "\n",
        "            if err_test < min_err_test:\n",
        "                min_err_test = err_test\n",
        "                best_c = C\n",
        "                best_tol = tol\n",
        "                best_max_iter = max_iter\n",
        "\n",
        "print(\"\\nMejores hiperparámetros (mínimo error de test):\")\n",
        "print(\"C = {:.4f}, tol = {:.1e}, max_iter = {}\".format(\n",
        "    best_c, best_tol, best_max_iter\n",
        "))\n",
        "print(\"Error de test mínimo = {:.2f}%\".format(min_err_test * 100))"
      ],
      "metadata": {
        "id": "IJjdYGQYZPw8",
        "outputId": "4f14e82f-bf67-43da-ff70-8a9c310d799f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|         C \t|       tol \t| max_it \t|  Err_train\t |   Err_test|\n",
            "------------------------------------------------------------------------------\n",
            "    0.0001\t|   1.0e-04\t|     10\t|      59.83\t|      59.93\n",
            "    0.0001\t|   1.0e-04\t|     25\t|      59.82\t|      59.93\n",
            "    0.0001\t|   1.0e-04\t|     50\t|      59.82\t|      59.93\n",
            "    0.0001\t|   1.0e-04\t|    100\t|      59.45\t|      59.40\n",
            "    0.0010\t|   1.0e-04\t|     10\t|      59.83\t|      59.93\n",
            "    0.0010\t|   1.0e-04\t|     25\t|      59.82\t|      59.93\n",
            "    0.0010\t|   1.0e-04\t|     50\t|      59.82\t|      59.93\n",
            "    0.0010\t|   1.0e-04\t|    100\t|      59.50\t|      59.47\n",
            "    0.0100\t|   1.0e-04\t|     10\t|      59.83\t|      59.93\n",
            "    0.0100\t|   1.0e-04\t|     25\t|      59.82\t|      59.93\n",
            "    0.0100\t|   1.0e-04\t|     50\t|      59.82\t|      59.93\n",
            "    0.0100\t|   1.0e-04\t|    100\t|      59.68\t|      59.86\n",
            "    0.1000\t|   1.0e-04\t|     10\t|      59.83\t|      59.93\n",
            "    0.1000\t|   1.0e-04\t|     25\t|      59.82\t|      59.93\n",
            "    0.1000\t|   1.0e-04\t|     50\t|      59.82\t|      59.93\n",
            "    0.1000\t|   1.0e-04\t|    100\t|      59.74\t|      59.91\n",
            "    1.0000\t|   1.0e-04\t|     10\t|      59.83\t|      59.93\n",
            "    1.0000\t|   1.0e-04\t|     25\t|      59.82\t|      59.93\n",
            "    1.0000\t|   1.0e-04\t|     50\t|      59.82\t|      59.93\n",
            "    1.0000\t|   1.0e-04\t|    100\t|      59.82\t|      59.93\n",
            "   10.0000\t|   1.0e-04\t|     10\t|      59.83\t|      59.93\n",
            "   10.0000\t|   1.0e-04\t|     25\t|      59.82\t|      59.93\n",
            "   10.0000\t|   1.0e-04\t|     50\t|      59.82\t|      59.93\n",
            "   10.0000\t|   1.0e-04\t|    100\t|      59.51\t|      59.54\n",
            "  100.0000\t|   1.0e-04\t|     10\t|      59.83\t|      59.93\n",
            "  100.0000\t|   1.0e-04\t|     25\t|      59.82\t|      59.93\n",
            "  100.0000\t|   1.0e-04\t|     50\t|      59.82\t|      59.93\n",
            "  100.0000\t|   1.0e-04\t|    100\t|      59.50\t|      59.57\n",
            "    0.0001\t|   1.0e-02\t|     10\t|      59.83\t|      59.93\n",
            "    0.0001\t|   1.0e-02\t|     25\t|      59.82\t|      59.93\n",
            "    0.0001\t|   1.0e-02\t|     50\t|      59.82\t|      59.93\n",
            "    0.0001\t|   1.0e-02\t|    100\t|      59.45\t|      59.40\n",
            "    0.0010\t|   1.0e-02\t|     10\t|      59.83\t|      59.93\n",
            "    0.0010\t|   1.0e-02\t|     25\t|      59.82\t|      59.93\n",
            "    0.0010\t|   1.0e-02\t|     50\t|      59.82\t|      59.93\n",
            "    0.0010\t|   1.0e-02\t|    100\t|      59.50\t|      59.47\n",
            "    0.0100\t|   1.0e-02\t|     10\t|      59.83\t|      59.93\n",
            "    0.0100\t|   1.0e-02\t|     25\t|      59.82\t|      59.93\n",
            "    0.0100\t|   1.0e-02\t|     50\t|      59.82\t|      59.93\n",
            "    0.0100\t|   1.0e-02\t|    100\t|      59.68\t|      59.86\n",
            "    0.1000\t|   1.0e-02\t|     10\t|      59.83\t|      59.93\n",
            "    0.1000\t|   1.0e-02\t|     25\t|      59.82\t|      59.93\n",
            "    0.1000\t|   1.0e-02\t|     50\t|      59.82\t|      59.93\n",
            "    0.1000\t|   1.0e-02\t|    100\t|      59.74\t|      59.91\n",
            "    1.0000\t|   1.0e-02\t|     10\t|      59.83\t|      59.93\n",
            "    1.0000\t|   1.0e-02\t|     25\t|      59.82\t|      59.93\n",
            "    1.0000\t|   1.0e-02\t|     50\t|      59.82\t|      59.93\n",
            "    1.0000\t|   1.0e-02\t|    100\t|      59.82\t|      59.93\n",
            "   10.0000\t|   1.0e-02\t|     10\t|      59.83\t|      59.93\n",
            "   10.0000\t|   1.0e-02\t|     25\t|      59.82\t|      59.93\n",
            "   10.0000\t|   1.0e-02\t|     50\t|      59.82\t|      59.93\n",
            "   10.0000\t|   1.0e-02\t|    100\t|      59.51\t|      59.54\n",
            "  100.0000\t|   1.0e-02\t|     10\t|      59.83\t|      59.93\n",
            "  100.0000\t|   1.0e-02\t|     25\t|      59.82\t|      59.93\n",
            "  100.0000\t|   1.0e-02\t|     50\t|      59.82\t|      59.93\n",
            "  100.0000\t|   1.0e-02\t|    100\t|      59.50\t|      59.57\n",
            "    0.0001\t|   1.0e+00\t|     10\t|      59.83\t|      59.93\n",
            "    0.0001\t|   1.0e+00\t|     25\t|      59.82\t|      59.93\n",
            "    0.0001\t|   1.0e+00\t|     50\t|      59.82\t|      59.93\n",
            "    0.0001\t|   1.0e+00\t|    100\t|      59.82\t|      59.93\n",
            "    0.0010\t|   1.0e+00\t|     10\t|      59.83\t|      59.93\n",
            "    0.0010\t|   1.0e+00\t|     25\t|      59.82\t|      59.93\n",
            "    0.0010\t|   1.0e+00\t|     50\t|      59.82\t|      59.93\n",
            "    0.0010\t|   1.0e+00\t|    100\t|      59.82\t|      59.93\n",
            "    0.0100\t|   1.0e+00\t|     10\t|      59.83\t|      59.93\n",
            "    0.0100\t|   1.0e+00\t|     25\t|      59.82\t|      59.93\n",
            "    0.0100\t|   1.0e+00\t|     50\t|      59.82\t|      59.93\n",
            "    0.0100\t|   1.0e+00\t|    100\t|      59.82\t|      59.93\n",
            "    0.1000\t|   1.0e+00\t|     10\t|      59.83\t|      59.93\n",
            "    0.1000\t|   1.0e+00\t|     25\t|      59.82\t|      59.93\n",
            "    0.1000\t|   1.0e+00\t|     50\t|      59.82\t|      59.93\n",
            "    0.1000\t|   1.0e+00\t|    100\t|      59.82\t|      59.93\n",
            "    1.0000\t|   1.0e+00\t|     10\t|      59.83\t|      59.93\n",
            "    1.0000\t|   1.0e+00\t|     25\t|      59.82\t|      59.93\n",
            "    1.0000\t|   1.0e+00\t|     50\t|      59.82\t|      59.93\n",
            "    1.0000\t|   1.0e+00\t|    100\t|      59.82\t|      59.93\n",
            "   10.0000\t|   1.0e+00\t|     10\t|      59.83\t|      59.93\n",
            "   10.0000\t|   1.0e+00\t|     25\t|      59.82\t|      59.93\n",
            "   10.0000\t|   1.0e+00\t|     50\t|      59.82\t|      59.93\n",
            "   10.0000\t|   1.0e+00\t|    100\t|      59.82\t|      59.93\n",
            "  100.0000\t|   1.0e+00\t|     10\t|      59.83\t|      59.93\n",
            "  100.0000\t|   1.0e+00\t|     25\t|      59.82\t|      59.93\n",
            "  100.0000\t|   1.0e+00\t|     50\t|      59.82\t|      59.93\n",
            "  100.0000\t|   1.0e+00\t|    100\t|      59.82\t|      59.93\n",
            "    0.0001\t|   1.0e+02\t|     10\t|      59.82\t|      59.93\n",
            "    0.0001\t|   1.0e+02\t|     25\t|      59.82\t|      59.93\n",
            "    0.0001\t|   1.0e+02\t|     50\t|      59.82\t|      59.93\n",
            "    0.0001\t|   1.0e+02\t|    100\t|      59.82\t|      59.93\n",
            "    0.0010\t|   1.0e+02\t|     10\t|      59.82\t|      59.93\n",
            "    0.0010\t|   1.0e+02\t|     25\t|      59.82\t|      59.93\n",
            "    0.0010\t|   1.0e+02\t|     50\t|      59.82\t|      59.93\n",
            "    0.0010\t|   1.0e+02\t|    100\t|      59.82\t|      59.93\n",
            "    0.0100\t|   1.0e+02\t|     10\t|      59.82\t|      59.93\n",
            "    0.0100\t|   1.0e+02\t|     25\t|      59.82\t|      59.93\n",
            "    0.0100\t|   1.0e+02\t|     50\t|      59.82\t|      59.93\n",
            "    0.0100\t|   1.0e+02\t|    100\t|      59.82\t|      59.93\n",
            "    0.1000\t|   1.0e+02\t|     10\t|      59.82\t|      59.93\n",
            "    0.1000\t|   1.0e+02\t|     25\t|      59.82\t|      59.93\n",
            "    0.1000\t|   1.0e+02\t|     50\t|      59.82\t|      59.93\n",
            "    0.1000\t|   1.0e+02\t|    100\t|      59.82\t|      59.93\n",
            "    1.0000\t|   1.0e+02\t|     10\t|      59.82\t|      59.93\n",
            "    1.0000\t|   1.0e+02\t|     25\t|      59.82\t|      59.93\n",
            "    1.0000\t|   1.0e+02\t|     50\t|      59.82\t|      59.93\n",
            "    1.0000\t|   1.0e+02\t|    100\t|      59.82\t|      59.93\n",
            "   10.0000\t|   1.0e+02\t|     10\t|      59.82\t|      59.93\n",
            "   10.0000\t|   1.0e+02\t|     25\t|      59.82\t|      59.93\n",
            "   10.0000\t|   1.0e+02\t|     50\t|      59.82\t|      59.93\n",
            "   10.0000\t|   1.0e+02\t|    100\t|      59.82\t|      59.93\n",
            "  100.0000\t|   1.0e+02\t|     10\t|      59.82\t|      59.93\n",
            "  100.0000\t|   1.0e+02\t|     25\t|      59.82\t|      59.93\n",
            "  100.0000\t|   1.0e+02\t|     50\t|      59.82\t|      59.93\n",
            "  100.0000\t|   1.0e+02\t|    100\t|      59.82\t|      59.93\n",
            "    0.0001\t|   1.0e+04\t|     10\t|      82.52\t|      82.82\n",
            "    0.0001\t|   1.0e+04\t|     25\t|      82.52\t|      82.82\n",
            "    0.0001\t|   1.0e+04\t|     50\t|      82.52\t|      82.82\n",
            "    0.0001\t|   1.0e+04\t|    100\t|      82.52\t|      82.82\n",
            "    0.0010\t|   1.0e+04\t|     10\t|      82.52\t|      82.82\n",
            "    0.0010\t|   1.0e+04\t|     25\t|      82.52\t|      82.82\n",
            "    0.0010\t|   1.0e+04\t|     50\t|      82.52\t|      82.82\n",
            "    0.0010\t|   1.0e+04\t|    100\t|      82.52\t|      82.82\n",
            "    0.0100\t|   1.0e+04\t|     10\t|      82.52\t|      82.82\n",
            "    0.0100\t|   1.0e+04\t|     25\t|      82.52\t|      82.82\n",
            "    0.0100\t|   1.0e+04\t|     50\t|      82.52\t|      82.82\n",
            "    0.0100\t|   1.0e+04\t|    100\t|      82.52\t|      82.82\n",
            "    0.1000\t|   1.0e+04\t|     10\t|      82.52\t|      82.82\n",
            "    0.1000\t|   1.0e+04\t|     25\t|      82.52\t|      82.82\n",
            "    0.1000\t|   1.0e+04\t|     50\t|      82.52\t|      82.82\n",
            "    0.1000\t|   1.0e+04\t|    100\t|      82.52\t|      82.82\n",
            "    1.0000\t|   1.0e+04\t|     10\t|      82.52\t|      82.82\n",
            "    1.0000\t|   1.0e+04\t|     25\t|      82.52\t|      82.82\n",
            "    1.0000\t|   1.0e+04\t|     50\t|      82.52\t|      82.82\n",
            "    1.0000\t|   1.0e+04\t|    100\t|      82.52\t|      82.82\n",
            "   10.0000\t|   1.0e+04\t|     10\t|      82.52\t|      82.82\n",
            "   10.0000\t|   1.0e+04\t|     25\t|      82.52\t|      82.82\n",
            "   10.0000\t|   1.0e+04\t|     50\t|      82.52\t|      82.82\n",
            "   10.0000\t|   1.0e+04\t|    100\t|      82.52\t|      82.82\n",
            "  100.0000\t|   1.0e+04\t|     10\t|      82.52\t|      82.82\n",
            "  100.0000\t|   1.0e+04\t|     25\t|      82.52\t|      82.82\n",
            "  100.0000\t|   1.0e+04\t|     50\t|      82.52\t|      82.82\n",
            "  100.0000\t|   1.0e+04\t|    100\t|      82.52\t|      82.82\n",
            "\n",
            "Mejores hiperparámetros (mínimo error de test):\n",
            "C = 0.0001, tol = 1.0e-04, max_iter = 100\n",
            "Error de test mínimo = 59.40%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}